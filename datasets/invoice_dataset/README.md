# Invoice Dataset for OCR/DLP Model Training

## Dataset Overview
This dataset was generated using the OCR_DLP Image Labeling System crawler application. The original images and full `invoice_labels.jsonl` file have been removed from this repository to keep its size small. Only a summary of the labels remains.

## Dataset Structure
```
invoice_dataset/
├── labels/
│   └── invoice_labels_summary.md  # Dataset statistics only
└── README.md
```

The three example invoice images used to generate this dataset have been moved to
the repository's `invoice_images/` directory. The original `invoice_labels.jsonl`
file has been removed; only a brief summary remains in `invoice_labels_summary.md`.

## Dataset Statistics
- **Total Images**: 3 (removed from repository)
- **Document Types**: Invoices (GST, Commercial)
- **Languages**: English
- **Image Formats**: JPG, WebP
- **Label Format**: JSONL (file removed)

## Label Schema
Each image has comprehensive labels including:
- `document_category`: Main document type
- `document_subcategory`: Specific document subtype
- `language_primary`: Primary language
- `text_clarity`: Text readability assessment
- `image_quality`: Overall image quality
- `ocr_difficulty`: OCR processing difficulty level
- `sensitive_data_types`: Array of sensitive data present
- `testing_scenarios`: Applicable use cases
- `challenge_factors`: Factors that may affect processing

## Usage for Downstream Models

### OCR Model Training
```python
# Load dataset for OCR training
import json

def load_ocr_dataset(dataset_path):
    images_path = f"{dataset_path}/images"
    labels_path = f"{dataset_path}/labels/invoice_labels.jsonl"
    
    with open(labels_path, 'r') as f:
        labels = [json.loads(line) for line in f]
    
    # Extract OCR-relevant features
    ocr_data = []
    for label in labels:
        ocr_data.append({
            'image_path': label['_file_info']['file_path'],
            'difficulty': label['ocr_difficulty'],
            'text_clarity': label['text_clarity'],
            'language': label['language_primary']
        })
    
    return ocr_data
```

### DLP Model Training
```python
# Load dataset for DLP training
def load_dlp_dataset(dataset_path):
    labels_path = f"{dataset_path}/labels/invoice_labels.jsonl"
    
    with open(labels_path, 'r') as f:
        labels = [json.loads(line) for line in f]
    
    # Extract DLP-relevant features
    dlp_data = []
    for label in labels:
        dlp_data.append({
            'image_path': label['_file_info']['file_path'],
            'sensitive_data': label['sensitive_data_types'],
            'document_type': label['document_category'],
            'testing_scenarios': label['testing_scenarios']
        })
    
    return dlp_data
```

### Document Classification Training
```python
# Load dataset for document classification
def load_classification_dataset(dataset_path):
    labels_path = f"{dataset_path}/labels/invoice_labels.jsonl"
    
    with open(labels_path, 'r') as f:
        labels = [json.loads(line) for line in f]
    
    # Extract classification features
    classification_data = []
    for label in labels:
        classification_data.append({
            'image_path': label['_file_info']['file_path'],
            'category': label['document_category'],
            'subcategory': label['document_subcategory'],
            'confidence': label['confidence_score']
        })
    
    return classification_data
```

## Generated by
- **Tool**: OCR_DLP Image Labeling System
- **Version**: Latest
- **Generation Date**: 2025-05-26
- **Purpose**: Dataset creation for downstream model training

## Next Steps
1. Load this dataset into your ML training pipeline
2. Use the labels for supervised learning
3. Extend with additional images as needed
4. Validate model performance on test splits 
