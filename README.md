# OCR_DLP Image Crawler & Dataset Generator

A comprehensive CLI application for **crawling images** and **generating labeled datasets** for OCR (Optical Character Recognition) and DLP (Data Loss Prevention) model training.

## ğŸ¯ Purpose

This is a **CRAWLER APPLICATION** that generates **LABELED DATASETS** for downstream model training. It crawls images from various sources and uses AI to generate comprehensive labels for training OCR, DLP, and document classification models.

**Workflow: CRAWLER â†’ LABELED DATASET â†’ DOWNSTREAM MODEL TRAINING**

### Key Features

- ğŸ” **Multi-Engine Image Search**: Serper, Google, Bing, DuckDuckGo integration
- ğŸ“¥ **Robust Image Download**: Automated download with validation and error handling
- ğŸ¤– **AI-Powered Labeling**: GPT-4V integration for intelligent document labeling
- ğŸ·ï¸ **Comprehensive Labels**: Multi-purpose labels for OCR, DLP, and classification training
- ğŸ“ **Dataset Generation**: Creates production-ready datasets with standard structure
- âš¡ **CLI Interface**: Professional command-line tool with subcommands
- âœ… **Quality Validation**: Built-in dataset quality checks
- â³ **Rate-Limit Handling**: Automatic retries with exponential backoff

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API key (for GPT-4V labeling)
- Serper API key (for image search)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd ocrdlp-lab
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set environment variables**
   ```bash
   # Windows
   set SERPER_API_KEY=your_serper_api_key
   set OPENAI_API_KEY=your_openai_api_key
   
   # Linux/Mac
   export SERPER_API_KEY=your_serper_api_key
   export OPENAI_API_KEY=your_openai_api_key
   ```

### Verify Installation

```bash
python ocrdlp.py --help
```

## ğŸ“‹ Dataset Generation Workflow

### 1. Search for Images

```bash
# Search for document images
python ocrdlp.py search "invoice documents" --engine serper --limit 100 --output urls.txt
```

### 2. Download Images

```bash
# Download images directly into the dataset
python ocrdlp.py download --urls-file urls.txt --output-dir ./datasets/invoice_dataset/images
```

### 3. Generate Dataset with Labels

```bash
# Create label directory
mkdir -p datasets/invoice_dataset/labels

# Generate comprehensive labels
python ocrdlp.py classify datasets/invoice_dataset/images --output datasets/invoice_dataset/labels/invoice_dataset_labels.jsonl
```

### 4. Validate Dataset Quality

```bash
# Validate generated dataset
python ocrdlp.py validate datasets/invoice_dataset/labels/invoice_dataset_labels.jsonl
```

## ğŸ—ï¸ Generated Dataset Structure

```
datasets/
â””â”€â”€ invoice_dataset/
    â”œâ”€â”€ images/              # Raw images for training
    â”‚   â”œâ”€â”€ image_001.jpg
    â”‚   â”œâ”€â”€ image_002.png
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ labels/              # AI-generated labels
    â”‚   â”œâ”€â”€ <dataset>_labels.jsonl     # Comprehensive labels
    â”‚   â””â”€â”€ <dataset>_labels_summary.md       # Dataset statistics
    â””â”€â”€ README.md            # Usage instructions for ML engineers
```

## ğŸ“Š Label Schema

Each image gets comprehensive labels for multiple downstream use cases:

- **Document Classification**: `document_category`, `document_subcategory`
- **OCR Training**: `ocr_difficulty`, `text_clarity`, `language_primary`
- **DLP Training**: `sensitive_data_types`, `testing_scenarios`
- **Quality Assessment**: `image_quality`, `background_complexity`
- **Processing Hints**: `recommended_preprocessing`, `challenge_factors`

## ğŸ¯ Downstream Model Usage

### OCR Model Training
```python
import json

def load_ocr_dataset(dataset_path):
    labels_path = f"{dataset_path}/labels/<dataset>_labels.jsonl"
    with open(labels_path, 'r') as f:
        labels = [json.loads(line) for line in f]
    
    return [{
        'image_path': label['_file_info']['file_path'],
        'difficulty': label['ocr_difficulty'],
        'text_clarity': label['text_clarity'],
        'language': label['language_primary']
    } for label in labels]
```

### DLP Model Training
```python
def load_dlp_dataset(dataset_path):
    labels_path = f"{dataset_path}/labels/<dataset>_labels.jsonl"
    with open(labels_path, 'r') as f:
        labels = [json.loads(line) for line in f]
    
    return [{
        'image_path': label['_file_info']['file_path'],
        'sensitive_data': label['sensitive_data_types'],
        'document_type': label['document_category']
    } for label in labels]
```

## ğŸ”§ CLI Commands

### Search Command
```bash
python ocrdlp.py search "document type" --engine serper --limit 50 --output urls.txt
```

### Download Command
```bash
python ocrdlp.py download --urls-file urls.txt --output-dir ./images
# OR
python ocrdlp.py download --query "invoice" --output-dir ./images --limit 20
```

### Classify Command
```bash
python ocrdlp.py classify ./images --output invoice_labels.jsonl --validate
```

### Pipeline Command (Complete Workflow)
```bash
python ocrdlp.py pipeline "invoice documents" --output-dir ./invoice_dataset --limit 50
```

### Validate Command
```bash
python ocrdlp.py validate invoice_labels.jsonl
```

## ğŸ‰ Example: Creating Invoice Dataset

```bash
# Complete workflow to create invoice training dataset
python ocrdlp.py pipeline "invoice documents" --output-dir ./datasets/invoices --limit 100

# Dataset is now ready at ./datasets/invoices/
# - images/ contains downloaded invoice images
    # - labels/invoice_dataset_labels.jsonl contains comprehensive labels
```

## ğŸ”Œ Offline Usage

The unit tests simulate the entire pipeline without making real network calls. This
is useful when API access is unavailable.

```bash
pip install -r requirements.txt
pytest
```

To try the CLI with predownloaded images, set dummy API keys and point the
`download` command at a text file of image URLs:

```bash
export SERPER_API_KEY=dummy
export OPENAI_API_KEY=dummy
ocrdlp download --urls-file sample_urls.txt --output-dir ./offline_demo
ocrdlp classify ./offline_demo/images --output offline_labels.jsonl
```

## ğŸ› ï¸ Development

### Run Tests
```bash
python test_viability.py
python test_image_labeling.py
```

### Direct Labeling (Alternative)
```bash
python gpt4v_image_labeler.py ./images invoice_labels.jsonl
```

## ğŸ“ˆ Key Benefits

1. **Automated Dataset Creation** - No manual labeling required
2. **Multi-Purpose Labels** - One dataset serves multiple model types  
3. **Production-Ready** - Standard ML dataset format
4. **Scalable** - Can generate thousands of labeled images
5. **Quality Assured** - Built-in validation and quality checks

---

**This is a CRAWLER for DATASET GENERATION, not a model evaluation tool.**

Generated datasets are ready for use in training OCR, DLP, and document classification models. 
## âš ï¸ Image Rights Reminder

When collecting images from search engines or photo sites (Google Images, Unsplash, etc.), verify that you have permission to use and redistribute each image. Check the licensing terms and respect copyright restrictions before sharing any dataset.
